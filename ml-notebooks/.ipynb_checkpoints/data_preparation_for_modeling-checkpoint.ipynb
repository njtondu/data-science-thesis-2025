{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation for Modeling\n",
        "\n",
        "This notebook prepares the passengers enriched data for machine learning modeling by:\n",
        "1. Dropping redundant fields\n",
        "2. Converting date to numerical and cyclical features\n",
        "3. Creating weekend boolean field\n",
        "4. Converting event type to boolean\n",
        "5. Handling null values in toilet fields\n",
        "6. Filling null values in service and parking fields with appropriate statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "…n,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the passengers enriched data\n",
        "df_original = pd.read_csv('../data/processed/passengers_enriched_2023.csv', low_memory=False)\n",
        "\n",
        "print(f\"Original dataset shape: {df_original.shape}\")\n",
        "print(f\"\\nColumn names: {df_original.columns.tolist()}\")\n",
        "print(f\"\\nData types:\")\n",
        "print(df_original.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "df_original.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Copy for Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy of the dataframe for processing\n",
        "df = df_original.copy()\n",
        "print(f\"Working dataset shape: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Drop Redundant Fields\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fields to drop as specified\n",
        "fields_to_drop = ['airportinterchange', 'hubnaptancode', 'station_name', 'mode', 'event_name']\n",
        "\n",
        "print(f\"Fields to drop: {fields_to_drop}\")\n",
        "print(f\"Shape before dropping: {df.shape}\")\n",
        "\n",
        "# Drop the fields\n",
        "df = df.drop(columns=fields_to_drop)\n",
        "\n",
        "print(f\"Shape after dropping: {df.shape}\")\n",
        "print(f\"Remaining columns: {df.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Convert Date to Numerical and Cyclical Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert date to datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Extract numerical features from date\n",
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "df['day'] = df['date'].dt.day\n",
        "df['day_of_year'] = df['date'].dt.dayofyear\n",
        "\n",
        "# Create cyclical features for month and day of year\n",
        "# Month cyclical features (12 months)\n",
        "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "\n",
        "# Day of year cyclical features (365/366 days)\n",
        "df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
        "df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
        "\n",
        "print(\"Date features created:\")\n",
        "print(df[['date', 'year', 'month', 'day', 'day_of_year', 'month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Weekend Boolean Field\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create is_weekend boolean field\n",
        "# Weekend is Saturday (5) and Sunday (6) in pandas weekday (Monday=0)\n",
        "df['is_weekend'] = df['date'].dt.weekday.isin([5, 6])\n",
        "\n",
        "print(\"Weekend distribution:\")\n",
        "print(df['is_weekend'].value_counts())\n",
        "print(f\"\\nPercentage of weekend days: {df['is_weekend'].mean()*100:.2f}%\")\n",
        "\n",
        "# Verify with dayofweek column\n",
        "print(\"\\nVerification with dayofweek column:\")\n",
        "print(pd.crosstab(df['dayofweek'], df['is_weekend']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Convert Event Type to Boolean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check current event_type values\n",
        "print(\"Current event_type values:\")\n",
        "print(df['event_type'].value_counts(dropna=False))\n",
        "print(f\"\\nNull values in event_type: {df['event_type'].isnull().sum()}\")\n",
        "print(f\"Total rows: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create is_event boolean field\n",
        "# If there is an event (not null), then 1, else 0\n",
        "df['is_event'] = df['event_type'].notna().astype(int)\n",
        "\n",
        "print(\"Event distribution:\")\n",
        "print(df['is_event'].value_counts())\n",
        "print(f\"\\nPercentage of days with events: {df['is_event'].mean()*100:.2f}%\")\n",
        "\n",
        "# Set expected_attendance to 0 when there's no event\n",
        "df.loc[df['is_event'] == 0, 'expected_attendance'] = 0\n",
        "\n",
        "print(f\"\\nExpected attendance after filling zeros: {df['expected_attendance'].describe()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fill Null Toilet Fields\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check current toilet field values\n",
        "print(\"Current toilet field values:\")\n",
        "print(\"\\ntoilet_isaccessible:\")\n",
        "print(df['toilet_isaccessible'].value_counts(dropna=False))\n",
        "print(\"\\ntoilet_isfeecharged:\")\n",
        "print(df['toilet_isfeecharged'].value_counts(dropna=False))\n",
        "print(\"\\ntoilet_type:\")\n",
        "print(df['toilet_type'].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill all null toilet fields with 'unknown'\n",
        "toilet_columns = ['toilet_isaccessible', 'toilet_isfeecharged', 'toilet_type']\n",
        "\n",
        "for col in toilet_columns:\n",
        "    df[col] = df[col].fillna('unknown')\n",
        "    print(f\"\\n{col} after filling:\")\n",
        "    print(df[col].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analyze and Fill Service/Parking Fields\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fields to analyze for null filling\n",
        "numeric_fields = ['service_operated_allweek_pct', 'service_operated_weekday_pct', \n",
        "                 'service_operated_weekend_pct', 'kilometres_operated', 'bluebadgecarparkspaces']\n",
        "\n",
        "print(\"Analysis of numeric fields with null values:\")\n",
        "for field in numeric_fields:\n",
        "    if field in df.columns:\n",
        "        null_count = df[field].isnull().sum()\n",
        "        total_count = len(df)\n",
        "        null_percentage = (null_count / total_count) * 100\n",
        "        \n",
        "        print(f\"\\n{field}:\")\n",
        "        print(f\"  Null values: {null_count} ({null_percentage:.2f}%)\")\n",
        "        \n",
        "        if null_count < total_count:  # If there are non-null values\n",
        "            mean_val = df[field].mean()\n",
        "            median_val = df[field].median()\n",
        "            std_val = df[field].std()\n",
        "            \n",
        "            print(f\"  Mean: {mean_val:.2f}\")\n",
        "            print(f\"  Median: {median_val:.2f}\")\n",
        "            print(f\"  Std: {std_val:.2f}\")\n",
        "            print(f\"  Skewness: {df[field].skew():.2f}\")\n",
        "            \n",
        "            # Recommend median if highly skewed, mean otherwise\n",
        "            if abs(df[field].skew()) > 1:\n",
        "                print(f\"  Recommendation: Use MEDIAN (data is skewed)\")\n",
        "            else:\n",
        "                print(f\"  Recommendation: Use MEAN (data is relatively normal)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize distributions to help decide between mean and median\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, field in enumerate(numeric_fields):\n",
        "    if field in df.columns and i < len(axes):\n",
        "        # Plot histogram\n",
        "        df[field].hist(bins=50, ax=axes[i], alpha=0.7)\n",
        "        axes[i].set_title(f'{field} Distribution')\n",
        "        axes[i].set_xlabel(field)\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "        \n",
        "        # Add mean and median lines\n",
        "        mean_val = df[field].mean()\n",
        "        median_val = df[field].median()\n",
        "        axes[i].axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
        "        axes[i].axvline(median_val, color='green', linestyle='--', label=f'Median: {median_val:.2f}')\n",
        "        axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill null values based on analysis\n",
        "# Using median for highly skewed data, mean for relatively normal data\n",
        "\n",
        "fill_strategies = {}\n",
        "\n",
        "for field in numeric_fields:\n",
        "    if field in df.columns:\n",
        "        skewness = df[field].skew()\n",
        "        \n",
        "        if abs(skewness) > 1:  # Highly skewed - use median\n",
        "            fill_value = df[field].median()\n",
        "            strategy = 'median'\n",
        "        else:  # Relatively normal - use mean\n",
        "            fill_value = df[field].mean()\n",
        "            strategy = 'mean'\n",
        "        \n",
        "        fill_strategies[field] = {'value': fill_value, 'strategy': strategy}\n",
        "        \n",
        "        # Fill null values\n",
        "        null_count_before = df[field].isnull().sum()\n",
        "        df[field] = df[field].fillna(fill_value)\n",
        "        null_count_after = df[field].isnull().sum()\n",
        "        \n",
        "        print(f\"{field}: Filled {null_count_before} null values with {strategy} = {fill_value:.2f}\")\n",
        "        print(f\"  Null values after filling: {null_count_after}\")\n",
        "\n",
        "print(\"\\nFill strategies summary:\")\n",
        "for field, info in fill_strategies.items():\n",
        "    print(f\"{field}: {info['strategy']} = {info['value']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of changes made\n",
        "print(\"=== DATA PREPARATION SUMMARY ===\")\n",
        "print(f\"Original dataset shape: {df_original.shape}\")\n",
        "print(f\"Processed dataset shape: {df.shape}\")\n",
        "print(f\"\\n1. Dropped fields: {fields_to_drop}\")\n",
        "print(f\"\\n2. Date features created:\")\n",
        "print(f\"   - year, month, day, day_of_year\")\n",
        "print(f\"   - month_sin, month_cos (cyclical)\")\n",
        "print(f\"   - day_of_year_sin, day_of_year_cos (cyclical)\")\n",
        "print(f\"\\n3. Boolean features created:\")\n",
        "print(f\"   - is_weekend: {df['is_weekend'].sum()} weekend records\")\n",
        "print(f\"   - is_event: {df['is_event'].sum()} event records\")\n",
        "print(f\"\\n4. Toilet fields filled with 'unknown' for null values\")\n",
        "print(f\"\\n5. Numeric fields filled with appropriate statistics:\")\n",
        "for field, info in fill_strategies.items():\n",
        "    print(f\"   - {field}: {info['strategy']} = {info['value']:.2f}\")\n",
        "\n",
        "print(f\"\\nFinal null values check:\")\n",
        "null_counts = df.isnull().sum()\n",
        "if null_counts.sum() == 0:\n",
        "    print(\"✅ No null values remaining!\")\n",
        "else:\n",
        "    print(\"⚠️ Remaining null values:\")\n",
        "    print(null_counts[null_counts > 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display final dataset info\n",
        "print(\"Final dataset info:\")\n",
        "print(df.info())\n",
        "print(f\"\\nFinal columns: {df.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few rows of processed data\n",
        "print(\"First few rows of processed data:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Processed Data (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to save the processed data\n",
        "# df.to_csv('../data/processed/passengers_enriched_2023_prepared.csv', index=False)\n",
        "# print(\"Processed data saved to '../data/processed/passengers_enriched_2023_prepared.csv'\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
